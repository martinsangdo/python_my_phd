{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "collections = db_client['db_migration']\n",
    "tb_article = collections['tb_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_URL = 'https://thenewhumanitarian.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_text_data(url):\n",
    "    try:\n",
    "        # Set up Chrome WebDriver\n",
    "        service = Service('../chromedriver') # or geckodriver for firefox\n",
    "        options = webdriver.ChromeOptions()\n",
    "        #options.add_argument('headless')\n",
    "        options.add_argument(\"disable-gpu\")\n",
    "        options.add_argument(\"--window-size=0,0\")\n",
    "        driver = webdriver.Chrome(service=service, options=options) # or webdriver.Firefox(service=service)\n",
    "\n",
    "        # Navigate to the webpage\n",
    "        driver.get(url)\n",
    "        # driver.minimize_window()\n",
    "        # driver.set_window_size(1, 1)\n",
    "\n",
    "        # Wait for JavaScript to load (adjust time as needed)\n",
    "        driver.implicitly_wait(10)  # Waits up to 10 seconds for elements to appear\n",
    "\n",
    "        # Get the rendered HTML\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        return soup\n",
    "    except:\n",
    "        print('Error when scraping webpage')\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_article_meta(article_detail):\n",
    "        db_article = tb_article.find_one({'url': article_detail['url']})\n",
    "        if db_article is None:\n",
    "            #insert\n",
    "            tb_article.insert_one(article_detail)\n",
    "            # print(\"Inserted +++++++++++ article: \" + article_detail['title'])\n",
    "        else:\n",
    "            #update\n",
    "            tb_article.update_one({'url': article_detail['url']}, {'$set': article_detail})\n",
    "            # print(\"Updated ............ article: \" + article_detail['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There may have different content type\n",
    "#1: normal article: (https://www.thenewhumanitarian.org/opinion/2025/02/04/how-europe-can-escape-migration-deterrence-trap)\n",
    "#2: report article: (https://www.thenewhumanitarian.org/analysis/2025/01/07/trends-will-spur-humanitarian-needs-2025)\n",
    "def extract_content(soup):\n",
    "    content = ''\n",
    "    #type 1\n",
    "    big_content = soup.find('div', attrs={'class': 'field-name-body flow'})\n",
    "    items = big_content.find_all('p')\n",
    "\n",
    "    no_of_paragraphs = len(items)\n",
    "    #print(str(no_of_paragraphs))\n",
    "    for i in range(0, no_of_paragraphs):\n",
    "        if i == no_of_paragraphs -1:\n",
    "            #this is the last item, we need to check whether it is note or not (https://www.thenewhumanitarian.org/opinion/2025/02/04/how-europe-can-escape-migration-deterrence-trap)\n",
    "            em_tag = items[i].find('em')\n",
    "            if em_tag is not None:\n",
    "                break   #do not include this paragraph in the final content\n",
    "        content += items[i].text.strip()\n",
    "    #type 2\n",
    "    items = soup.find_all('div', attrs={'class': 'advanced-report-content flow'})\n",
    "    no_of_paragraphs = len(items)\n",
    "    #print(str(no_of_paragraphs))\n",
    "    for i in range(0, no_of_paragraphs):\n",
    "        p = items[i].find_all('p')\n",
    "        for j in range(0, len(p)):\n",
    "            content += p[j].text.strip()\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated content: /investigations/2024/10/16/risk-return-israel-bombs-lebanon-syrian-deportees-face-detention\n",
      "Updated content: /news/2025/03/07/aid-cut-fallout-gaza-israel-blockade-ukraine-future-cheat-sheet\n",
      "Updated content: /news/2025/02/28/us-termination-notices-drc-bukavu-blasts-colonialism-oscars-cheat-sheet\n",
      "Updated content: /news/2025/02/21/humanitarian-aid-system-reboot-germany-high-stakes-polls-elections-sudan-massacre\n",
      "Updated content: /news/2025/02/14/trump-aid-exemptions-one-sided-ukraine-talks-and-busy-au-summit-cheat-sheet\n",
      "Updated content: /opinion/2024/10/15/humanitarians-stop-using-fear-migration-drive-fundraising-advocacy-aid\n",
      "Updated content: /news/2024/10/09/uk-seeks-move-36-diego-garcia-asylum-seekers-romania\n",
      "Updated content: /news/2024/10/08/exclusive-uk-agrees-admit-some-diego-garcia-asylum-seekers\n",
      "Updated content: /news/2024/10/03/uk-hands-back-chagos-islands-mauritius\n",
      "Updated content: /news-feature/2024/09/26/lebanons-migrant-workers-left-stranded-homeless-israeli-attacks\n",
      "Updated content: /news-feature/2024/09/18/dodgy-migration-deterrence-deals-drug-cartels-aid-barriers-darien-gap-colombia-panama\n",
      "Updated content: /feature/2024/09/12/dadaab-voices-kenyas-flagship-refugee-plan-marred-lack-consultation\n",
      "Updated content: /analysis/2024/08/14/what-refugee-rentierism-explainer\n",
      "Updated content: /news-feature/2024/08/01/niger-tries-new-refugee-model-nigerians-flee-bandit-attacks\n",
      "Updated content: /analysis/2024/07/31/drowning-sexual-violence-or-robbery-pick-your-route-through-darien-gap\n",
      "Updated content: /opinion/2024/07/25/es-hora-de-actuar-por-que-no-podemos-ignorar-el-riesgo-de-un-nuevo-exodo\n",
      "Updated content: /opinion/2024/07/25/its-time-act-why-we-cant-overlook-risk-new-exodus-venezuela\n",
      "Updated content: /analysis/2024/07/17/why-these-10-humanitarian-crises-still-demand-your-attention\n",
      "Updated content: /news/2024/07/11/armed-men-disrupt-mediterranean-migration-boat-rescues\n",
      "Updated content: /news/2024/07/09/us-blocks-diego-garcia-asylum-seekers-detention-hearing\n",
      "Updated content: /news/2024/07/08/160-dead-or-missing-atlantic-migrant-crossing\n",
      "Updated content: /news-feature/2024/07/04/tamils-allege-prison-conditions-diego-garcia-ahead-unlawful-detention\n",
      "Updated content: /news/2024/07/02/us-panama-announce-plan-stop-darien-migration\n",
      "Updated content: /opinion/first-person/2024/07/02/can-greece-illegal-pushback-system-be-broken-migration\n",
      "Error when scraping webpage\n",
      "Error no soup: /news/2024/06/20/world-refugee-day-reading-list-forced-displacement-hits-record-levels\n",
      "Updated content: /news/2024/06/19/egypt-forcibly-deporting-sudanese-refugees-amnesty\n",
      "Updated content: /news-feature/2024/06/19/deaths-migration-route-canary-islands-spain-soar-1000-month\n"
     ]
    }
   ],
   "source": [
    "#find article that haven't scraped its content\n",
    "db_articles = tb_article.find({'is_scraped': 0})\n",
    "if db_articles is not None:\n",
    "    for db_article in db_articles:\n",
    "        url = db_article['url']\n",
    "        soup = scrape_text_data(DOMAIN_URL + url)\n",
    "        if soup == '':\n",
    "            print('Error no soup: ' + url)\n",
    "            db_article['error'] = 'no soup'\n",
    "            tb_article.update_one({'url': url}, {'$set': db_article})\n",
    "        else:\n",
    "            db_article['is_scraped'] = 1\n",
    "            content = extract_content(soup)\n",
    "            if content == '':\n",
    "                db_article['error'] = 'no content'\n",
    "                tb_article.update_one({'url': url}, {'$set': db_article})\n",
    "                print('Error content in page: ' + url)\n",
    "            else:\n",
    "                #correct data\n",
    "                db_article['error'] = ''\n",
    "                db_article['content'] = content\n",
    "                db_article['len_content'] = len(content)\n",
    "                tb_article.update_one({'url': url}, {'$set': db_article})\n",
    "                # print(content)\n",
    "                print('Updated content: ' + url)\n",
    "        time.sleep(1)   #delay for 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
