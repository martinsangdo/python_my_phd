{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape articles from multiple sources\n",
    "#can use free scraping API free online? -> no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://www.thenewhumanitarian.org/\n",
    "https://www.thenewhumanitarian.org/rss/all.xml\n",
    "-> ok\n",
    "2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking Gemini: is this article related closely to the topic forced displacement? https://www.thenewhumanitarian.org/film/why-are-honduran-farmers-being-forced-urban-gang-areas -> this is only video\n",
    "\n",
    "-> Yes, this article is related closely to the topic forced displacement. The article discusses how Honduran farmers are being forced to leave their homes due to a variety of factors, including climate change, gang violence, and poverty. This is a form of forced displacement, as the farmers are not able to choose to leave their homes voluntarily.\n",
    "\n",
    "Is this article related closely to the topic of forced displacement? https://www.thenewhumanitarian.org/opinion/first-person/2024/02/20/sudan-war-sudanese-journalist-describes-horror-she-cannot-cover\n",
    "-> No, this article is not related closely to the topic of forced displacement, according to the article. Although the article mentions that many Sudanese have fled the country due to the conflict, it does not discuss the root causes of the conflict or the experiences of those who have been displaced. Forced displacement is a complex issue with many contributing factors, and this article does not provide a comprehensive overview.\n",
    "\n",
    "Is this article related closely to the topic of forced displacement? https://www.thenewhumanitarian.org/opinion/2024/06/11/denial-humanitarian-assistance-death-sentence-myanmar\n",
    "-> Yes, this article is related to forced displacement. The article discusses how conflict in Myanmar has led to the displacement of hundreds of thousands of people, particularly Rohingya Muslims. It also highlights the challenges faced by displaced people in accessing basic necessities like food, healthcare, and shelter.\n",
    "\n",
    "Is this article related closely to the topic of forced displacement? https://www.thenewhumanitarian.org/interview/2024/05/29/arakan-army-responds-rohingya-abuse-accusations-myanmar\n",
    "-> Yes, this article is related closely to the topic of forced displacement. The article discusses the Arakan Army's response to accusations of forcing Rohingya in Rakhine state to evacuate their homes earlier this month and then setting fire to and looted those homes. [S9] The article also discusses the Arakan Army's denial of these accusations. [S10]\n",
    "\n",
    "\n",
    "Is this article related closely to the topic of forced displacement? https://www.thenewhumanitarian.org/news-feature/2024/09/26/inside-effort-help-gaza-university-students-continue-education-studies\n",
    "-> While I aim to be helpful, Google Search may provide a more detailed and accurate response on this topic.\n",
    "-> The article is somewhat related to forced displacement.\n",
    "While the article itself doesn't explicityly mention forced displacement, it does discuss the challenges students face in accessing education after the war [S5, S6, S7]. Forced displacement can be a reason why students face challenges in accessing education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.thenewhumanitarian.org/news-feature/2024/09/26/inside-effort-help-gaza-university-students-continue-education-studies\"\n",
    "url = 'https://www.thenewhumanitarian.org/news-feature/2025/03/06/gaza-strip-israel-aid-blockade-deeper-humanitarian-crisis'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.zenrows.com/blog/python-requests-proxy#perform-requests\n",
    "proxy_addresses = {\n",
    "    'http': 'http://46.47.197.210:3128',\n",
    "    'https': 'http://35.198.189.129:8080'\n",
    "}\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_url = 'https://www.thenewhumanitarian.org/migration?page=0'\n",
    "# response = requests.get(list_url, headers=headers) #-> this is only get source of javascript\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient('mongodb://localhost:27017')\n",
    "collections = db_client['db_migration']\n",
    "tb_article = collections['tb_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_article_meta(article_detail):\n",
    "        db_article = tb_article.find_one({'url': article_detail['url']})\n",
    "        if db_article is None:\n",
    "            #insert\n",
    "            tb_article.insert_one(article_detail)\n",
    "            # print(\"Inserted +++++++++++ article: \" + article_detail['title'])\n",
    "        else:\n",
    "            #update\n",
    "            tb_article.update_one({'url': article_detail['url']}, {'$set': article_detail})\n",
    "            # print(\"Updated ............ article: \" + article_detail['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_text_data(url):\n",
    "    try:\n",
    "        # Set up Chrome WebDriver\n",
    "        service = Service('../chromedriver') # or geckodriver for firefox\n",
    "        options = webdriver.ChromeOptions()\n",
    "        #options.add_argument('headless')\n",
    "        options.add_argument(\"disable-gpu\")\n",
    "        options.add_argument(\"--window-size=0,0\")\n",
    "        driver = webdriver.Chrome(service=service, options=options) # or webdriver.Firefox(service=service)\n",
    "\n",
    "        # Navigate to the webpage\n",
    "        driver.get(url)\n",
    "        # driver.minimize_window()\n",
    "        # driver.set_window_size(1, 1)\n",
    "\n",
    "        # Wait for JavaScript to load (adjust time as needed)\n",
    "        driver.implicitly_wait(10)  # Waits up to 10 seconds for elements to appear\n",
    "\n",
    "        # Get the rendered HTML\n",
    "        html = driver.page_source\n",
    "\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "        # Parse the HTML with BeautifulSoup\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        return soup\n",
    "    except:\n",
    "        print('Error when scraping webpage: ' + url)\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish scraping page: 0\n",
      "Finish scraping page: 1\n",
      "Finish scraping page: 2\n",
      "Finish scraping page: 3\n",
      "Finish scraping page: 4\n",
      "Finish scraping page: 5\n",
      "Error when scraping webpage\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m soup \u001b[38;5;241m=\u001b[39m scrape_text_data(list_url)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soup \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mError content in page: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:   \n\u001b[1;32m     11\u001b[0m     items \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteaser-list__item\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "#get list of url in page\n",
    "list_url = 'https://www.thenewhumanitarian.org/migration?page=0'\n",
    "max_index = 16000   #thenewhumanitarian.org\n",
    "max_pages = 1000    #assuming we have 1000 pages\n",
    "for i in range(0, max_pages):\n",
    "    list_url = 'https://www.thenewhumanitarian.org/migration?page=' + str(i)\n",
    "    soup = scrape_text_data(list_url)\n",
    "    if soup == '':\n",
    "        print('Error content in page: ' + str(i))\n",
    "    else:   \n",
    "        items = soup.find_all('li', attrs={'class': 'teaser-list__item'})\n",
    "        if len(items) == 0:\n",
    "            print('Empty scrape page ' + str(i))\n",
    "            break\n",
    "        long_text = ''\n",
    "        for item in items:\n",
    "            if item.find('a')['href'] is not None or item.find('a')['href'] != '':\n",
    "                article_detail = {\n",
    "                    'category': item.find('li', attrs={'class': 'meta-list__item meta-list__item--theme'}).text,\n",
    "                    'date': item.find('span', attrs={'class': 'date--long'})['content'],\n",
    "                    'url': item.find('a')['href'],\n",
    "                    'title': item.find('h3', attrs={'class': 'teaser__title'}).text.strip(),\n",
    "                    'content': '',\n",
    "                    'len_content': 0,\n",
    "                    'is_scraped': 0\n",
    "                }\n",
    "                #upsert db\n",
    "                upsert_article_meta(article_detail)\n",
    "            else:\n",
    "                print('Empty url in page ' + str(i))\n",
    "                break\n",
    "    print('Finish scraping page: ' + str(i))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
